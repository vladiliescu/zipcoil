{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-07-14T07:06:25.518718Z",
     "start_time": "2025-07-14T07:06:25.348855Z"
    }
   },
   "source": [
    "import os\n",
    "from openai import AzureOpenAI\n",
    "\n",
    "client = AzureOpenAI(\n",
    "    api_key=os.getenv(\"AZURE_OPENAI_API_KEY\"),\n",
    "    azure_endpoint=os.getenv(\"AZURE_OPENAI_API_BASE\"),\n",
    "    api_version=os.getenv(\"AZURE_OPENAI_API_VERSION\")\n",
    ")\n",
    "openai_chatmodel = os.getenv(\"AZURE_OPENAI_CHAT_MODEL\")"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-14T07:06:39.522719Z",
     "start_time": "2025-07-14T07:06:37.338413Z"
    }
   },
   "cell_type": "code",
   "source": [
    "query = \"What is the homepage of Vlad Iliescu? What is the content of that page?\"\n",
    "\n",
    "completion = client.chat.completions.create(\n",
    "    model=openai_chatmodel,\n",
    "    messages=[{\"role\": \"user\", \"content\": query}],\n",
    "    temperature=0.0\n",
    ")\n",
    "\n",
    "print(completion.choices[0].message.content)\n",
    "\n"
   ],
   "id": "6688a1f0add308bf",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "As of my last knowledge update in October 2023, I do not have specific information about Vlad Iliescu's homepage or its content. If you are looking for details about a specific individual, I recommend performing a web search using their name to find their official website or online profiles. Always ensure you are accessing legitimate and verified sources.\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-14T07:25:04.606604Z",
     "start_time": "2025-07-14T07:24:58.432604Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "import html\n",
    "import re\n",
    "from html.parser import HTMLParser\n",
    "import json\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import urllib\n",
    "\n",
    "GRAY = \"\\033[90m\"\n",
    "BOLD = \"\\033[1m\"\n",
    "RESET = \"\\033[0m\"\n",
    "\n",
    "\n",
    "def get_search_results_for(query):\n",
    "    encoded_query = urllib.parse.urlencode({'q': query})\n",
    "    url = f'https://html.duckduckgo.com/html?q={encoded_query}'\n",
    "\n",
    "    request = urllib.request.Request(url)\n",
    "    request.add_header('User-Agent', 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_6) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/87.0.4280.88 Safari/537.36')\n",
    "\n",
    "    raw_response = urllib.request.urlopen(request).read()\n",
    "    html = raw_response.decode(\"utf-8\")\n",
    "\n",
    "    soup = BeautifulSoup(html, 'html.parser')\n",
    "    a_results = soup.select(\"a.result__a\")\n",
    "\n",
    "    links = []\n",
    "    for a_result in a_results:\n",
    "        # print(a_result)\n",
    "        url = a_result.attrs['href']\n",
    "        title = a_result.text\n",
    "        links.append({\"title\": title,  \"url\": url} )\n",
    "\n",
    "    return links\n",
    "\n",
    "class HTMLToTextParser(HTMLParser):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.text = []\n",
    "        self.ignore_tags = {'script', 'style', 'meta', 'link'}\n",
    "        self.current_tag = None\n",
    "\n",
    "    def handle_starttag(self, tag, attrs):\n",
    "        self.current_tag = tag\n",
    "        if tag in ['h1', 'h2', 'h3', 'h4', 'h5', 'h6']:\n",
    "            self.text.append(f\"\\n{'#' * int(tag[1])} \")\n",
    "        elif tag == 'p':\n",
    "            self.text.append('\\n\\n')\n",
    "        elif tag == 'br':\n",
    "            self.text.append('\\n')\n",
    "        elif tag == 'li':\n",
    "            self.text.append('\\n- ')\n",
    "\n",
    "    def handle_endtag(self, tag):\n",
    "        if tag in ['h1', 'h2', 'h3', 'h4', 'h5', 'h6']:\n",
    "            self.text.append('\\n')\n",
    "        self.current_tag = None\n",
    "\n",
    "    def handle_data(self, data):\n",
    "        if self.current_tag not in self.ignore_tags:\n",
    "            self.text.append(data.strip())\n",
    "\n",
    "    def get_text(self):\n",
    "        result = ''.join(self.text)\n",
    "        # Clean up extra whitespace\n",
    "        result = re.sub(r'\\n\\s*\\n', '\\n\\n', result)\n",
    "        return html.unescape(result.strip())\n",
    "\n",
    "def html_to_simple_text(html_content):\n",
    "    parser = HTMLToTextParser()\n",
    "    parser.feed(str(html_content))\n",
    "    return parser.get_text()\n",
    "\n",
    "\n",
    "def load_page_content(url) -> str:\n",
    "    response = requests.get(url, headers={'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_6) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/87.0.4280.88 Safari/537.36'})\n",
    "    page_content = response.content.decode('utf-8')\n",
    "\n",
    "    soup = BeautifulSoup(page_content, 'html.parser')\n",
    "    for element in soup(['script', 'style', 'meta', 'link']):\n",
    "        element.decompose()\n",
    "\n",
    "    return html_to_simple_text(soup)\n",
    "\n",
    "def get_homepage(blogger: str) -> str:\n",
    "    return \"https://vladiliescu.net\"\n",
    "    # return get_search_results_for(f\"{blogger} homepage\")[0][\"url\"]\n",
    "\n",
    "\n",
    "tools = [{\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "            \"name\": \"get_homepage\",\n",
    "            \"description\": \"Returns the homepage of a particular blogger.\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"blogger\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"description\": \"Blogger name\"\n",
    "                    }\n",
    "                },\n",
    "                \"required\": [\n",
    "                    \"blogger\"\n",
    "                ],\n",
    "                \"additionalProperties\": False\n",
    "            },\n",
    "            \"strict\": True\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "            \"name\": \"load_page_content\",\n",
    "            \"description\": \"Returns the content of a particular webpage.\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"url\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"description\": \"Url of the webpage for which to retrieve the content\"\n",
    "                    }\n",
    "                },\n",
    "                \"required\": [\n",
    "                    \"url\"\n",
    "                ],\n",
    "                \"additionalProperties\": False\n",
    "            },\n",
    "            \"strict\": True\n",
    "        }\n",
    "    }\n",
    "]\n",
    "\n",
    "def call_function(name, args):\n",
    "    if name == \"get_homepage\":\n",
    "        return get_homepage(**args)\n",
    "    if name == \"load_page_content\":\n",
    "        return load_page_content(**args)\n",
    "\n",
    "\n",
    "\n",
    "messages = [{\"role\": \"user\", \"content\": query}]\n",
    "\n",
    "total_input_token_count = 0\n",
    "total_output_token_count = 0\n",
    "\n",
    "while (True):\n",
    "    completion = client.chat.completions.create(\n",
    "        model=openai_chatmodel,\n",
    "        messages=messages,\n",
    "        tools=tools\n",
    "    )\n",
    "\n",
    "    total_input_token_count += completion.usage.prompt_tokens\n",
    "    total_output_token_count += completion.usage.completion_tokens\n",
    "\n",
    "    if completion.choices[0].finish_reason == \"stop\":\n",
    "        print(f\"{BOLD}Final answer: {completion.choices[0].message.content}{RESET}\")\n",
    "        break\n",
    "    elif completion.choices[0].finish_reason == \"tool_calls\":\n",
    "        messages.append(completion.choices[0].message)\n",
    "        for tool_call in completion.choices[0].message.tool_calls:\n",
    "            name = tool_call.function.name\n",
    "            args = json.loads(tool_call.function.arguments)\n",
    "\n",
    "            result = call_function(name, args)\n",
    "            print(f\"Called {BOLD}{name}({args}){RESET} and it returned {GRAY}{result[:300]}{RESET}\")\n",
    "\n",
    "            messages.append({\n",
    "                \"role\": \"tool\",\n",
    "                \"tool_call_id\": tool_call.id,\n",
    "                \"content\": result\n",
    "            })\n",
    "    else:\n",
    "        raise Exception(\"We're not supposed to be here\")\n"
   ],
   "id": "3b7060e7d75651bf",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Called \u001B[1mget_homepage({'blogger': 'Vlad Iliescu'})\u001B[0m and it returned \u001B[90mhttps://vladiliescu.net\u001B[0m\n",
      "Called \u001B[1mload_page_content({'url': 'https://vladiliescu.net'})\u001B[0m and it returned \u001B[90mVlad IliescuVlad Iliescu\n",
      "- âœ¨Awesomeâœ¨ Gen AI\n",
      "- Search\n",
      "- Talks ðŸŽ™\n",
      "- Apps\n",
      "- Wiki ðŸ“š\n",
      "- Archive\n",
      "# Hi, Iâ€™m Vlad ðŸ‘‹\n",
      "\n",
      "Iâ€™m a software & AI architect,founder, andMicrosoft MVP on AI.\n",
      "Iwriteandspeakabout machine learning in general and AI in particular. Follow me onSubstackor plain oldRSS.\n",
      "\n",
      "Here are some of my hi\u001B[0m\n",
      "\u001B[1mFinal answer: The homepage of Vlad Iliescu is [https://vladiliescu.net](https://vladiliescu.net).\n",
      "\n",
      "The content of the page includes an introduction to Vlad Iliescu, who is a software and AI architect, founder, and AI enthusiast, holding the Microsoft MVP title. His site details his contributions to AI research, applications, and various projects. It also includes blog posts, guides, and updates on various topics such as:\n",
      "\n",
      "- His work in co-founding AI ventures like **ZenAIos** (in the medical sector) and **NRGI.ai** (focused on energy forecasting and supply).\n",
      "- His involvement with AI outsourcing companies and conferences like **Strongbytes**, **Maxcode**, and **NDR**.\n",
      "- Blog entries covering diverse AI topics such as model fine-tuning costs, dependency injection in Python, experimenting with prompt caching, and building internet-connected search assistants.\n",
      "\n",
      "The website also redirects to additional resources, guides, and tools he has developed, such as apps, GitHub repositories, and Chrome extensions. Visitors are encouraged to interact with him through various social platforms linked on the site.\u001B[0m\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "2505ee29ec6c2cb8"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
